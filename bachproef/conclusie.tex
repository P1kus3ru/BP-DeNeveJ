%%=============================================================================
%% Conclusie
%%=============================================================================

\chapter{Conclusie}%
\label{ch:conclusie}

% TODO: Trek een duidelijke conclusie, in de vorm van een antwoord op de
% onderzoeksvra(a)g(en). Wat was jouw bijdrage aan het onderzoeksdomein en
% hoe biedt dit meerwaarde aan het vakgebied/doelgroep?
% Reflecteer kritisch over het resultaat. In Engelse teksten wordt deze sectie
% ``Discussion'' genoemd. Had je deze uitkomst verwacht? Zijn er zaken die nog
% niet duidelijk zijn?
% Heeft het onderzoek geleid tot nieuwe vragen die uitnodigen tot verder
%onderzoek?

Het onderzoek richtte zich op het gebruik van AI om stotterpatiënten een meer interactieve ervaring te bieden door spraakherkenningstechnologie toe te passen. De onderzoeksvragen waren gericht op het registreren van spraak, potentiële problemen bij spraakregistratie, de invloed van stotteraspecten op spraakherkenning en hoe de applicatie volgende spraakfragmenten kiest op basis van gegenereerde tekst.

Uit de literatuurstudie kwamen verschillende obstakels aan bod zoals domeinproblemen, natuurlijke taalverwerking problemen en de efficiëntie van de apparatuur. Aangezien de fragmenten bestonden uit video's van het Nederlandse YouTube kanaal 'StotterFonds', was er van achtergrond lawaai en meerdere sprekers geen probleem. Ook de taal en dialecten gaven geen moeilijkheid hoewel er geen duidelijkheid is hoe Belgisch Nederlands een verschil kan maken. Het domein waarin de modellen getraind zijn en de use case komen daarentegen niet overeen. De gebruikte modellen zijn gedoeld voor alledaags Nederlands en niet getraind op stotteren. De aanwezige obstakels bij de spraakherkenning van stottermomenten zijn vooral het herhalen van woorden en de blokkeringen. Deze zorgen ervoor dat de ASR de haperingen wilt registreren als aparte woorden of het woord meermaals achter elkaar zet. Dit was vooral op te vallen bij Azure.

De spraak wordt in de POC applicatie aan de hand van het gekozen invoerapparaat geregistreerd via een vooraf gekozen push-to-talk toets. Waarna het gecreëerde audiofragment met het gekozen model wordt verwerkt. Op basis van de resultaten blijkt het medium model van Whisper de beste optie voor het transcriberen van stotterpatiënten. Zo blijft de tijd en nauwkeurigheid van het model consistent over de fragmenten heen hoewel de duur wat langer is dan het Azure en kleine Whisper model. Die modellen hebben echter een hogere WER, vooral bij stotterfragmenten. Google is daarentegen uitgesloten dankzij de lange tijd die het neemt om een fragment te verwerken. Als laatste is het kiezen van een vervolg fragment op basis van wat de spreker antwoord is niet tot stand gekomen binnen de tweede examenperiode.

De uitslag van dit onderzoek had ik niet verwacht. Zo veronderstelde ik op voorhand dat de betaalde services van Google of Microsoft de bovenhand zouden hebben tegenover de open source Whisper. Ik wist dat de open source community niet te onderschatten was met de vele bijdragers maar toch dacht ik dat de grote namen beter zouden presteren. Daarnaast ben ik teleurgesteld in mezelf en vind ik het jammer dat ik er niet in ben geslaagd om het kiezen van een vervolg fragment te realiseren.

Aangezien dit onderzoek was uitgevoerd in het kader van het 360° Zorglab, bieden de resultaten een meerwaarde. Hopelijk kunnen ze aan de hand van de cijfers en de POC verdere ideeën uitwerken om effectief toe te passen in hun stottertherapie of andere doeleinden. Ook kan deze paper als basis gebruikt worden om verder onderzoek naar spraakherkenning van stotterpatiënten uit te voeren of om het schakelen van fragmenten uit te werken en te implementeren. Zo kan er mogelijks onderzoek gedaan worden naar hoe het Zorglab zelf een model kan maken met de data die ze in hun sessies verzamelen.

