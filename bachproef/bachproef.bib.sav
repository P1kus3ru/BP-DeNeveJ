% Encoding: UTF-8

@book{Knuth1998,
 author = {Knuth, Donald E.},
 title = {The art of computer programming,  volume 3: (2nd ed.) sorting and searching},
 year = {1998},
 publisher = {Addison Wesley Longman Publishing Co., Inc.},
 address = {Redwood City, CA, USA}
}

@book{Pollefliet2011,
  author = {Pollefliet, Leen},
  title = {Schrijven van verslag tot eindwerk: do's en don'ts},
  year = {2011},
  publisher = {Academia Press},
  address = {Gent}
}

@article{Creeger2009,
  author = {Creeger, Mache},
  journal = {Communications of the ACM},
  number = {8},
  pages = {50--56},
  title = {{CTO Roundtable: Cloud Computing}},
  volume = {52},
  year = {2009}
}

@InProceedings{Traum2015,
  author    = {Traum, David and Jones, Andrew and Hays, Kia and Maio, Heather and Alexander, Oleg and Artstein, Ron and Debevec, Paul and Gainer, Alesia and Georgila, Kallirroi and Haase, Kathleen and Jungblut, Karen and Leuski, Anton and Smith, Stephen and Swartout, William},
  booktitle = {Interactive Storytelling},
  date      = {2015},
  title     = {New Dimensions in Testimony: Digitally Preserving a Holocaust Survivor's Interactive Storytelling},
  editor    = {Schoenau-Fog, Henrik and Bruni, Luis Emilio and Louchart, Sandy and Baceviciute, Sarune},
  isbn      = {978-3-319-27036-4},
  location  = {Cham},
  pages     = {269--281},
  publisher = {Springer International Publishing},
  urldate   = {2022-12-12},
  abstract  = {We describe a digital system that allows people to have an interactive conversation with a human storyteller (a Holocaust survivor) who has recorded a number of dialogue contributions, including many compelling narratives of his experiences and thoughts. The goal is to preserve as much as possible of the experience of face-to-face interaction. The survivor's stories, answers to common questions, and testimony are recorded in high fidelity, and then delivered interactively to an audience as responses to spoken questions. People can ask questions and receive answers on a broad range of topics including the survivor's experiences before, after and during the war, his attitudes and philosophy. Evaluation results show that most user questions can be addressed by the system, and that audiences are highly engaged with the resulting interaction.},
}

@Online{Meta2022,
  author  = {Meta},
  date    = {2022-06-15},
  title   = {The Impact Will Be Real},
  url     = {https://www.youtube.com/watch?v=80IIEnSNwQc},
  urldate = {2022-12-11},
}

@Online{USF2020,
  author  = {{USC Shoah Foundation}},
  date    = {2020-04-03},
  title   = {Dimensions in Testimony | USC Shoah Foundation},
  url     = {https://www.youtube.com/watch?v=nGzAc9mIoTM},
  urldate = {2022-12-05},
}

@Thesis{Roepke2019,
  author      = {Röpke, Willem},
  date        = {2019},
  institution = {Vrije Universiteit Brussel},
  title       = {Een spraak-naar-tekst applicatie bouwen voor Nederlands},
  type        = {candthesis},
  urldate     = {2022-12-15},
}

@Article{Hessen2017,
  author       = {van Hessen, Arjan and van den Heuvel, Henk and van Gompel, Maarten},
  date         = {2017},
  journaltitle = {Dixit. Tijdschrift over toegepaste taal- en spraaktechnologie},
  title        = {Spreek2Schrijf},
  issn         = {1572-6037},
  pages        = {20-21},
  urldate      = {2022-12-15},
  volume       = {14},
}

@Thesis{Sterckx2018,
  author      = {Sterckx, Lucas},
  date        = {2018},
  institution = {Universiteit Gent},
  title       = {Methoden voor efficiënte supervisie van automatische taalverwerking},
  type        = {phdthesis},
  urldate     = {2022-12-15},
}

@InProceedings{Leuski2010,
  author    = {Leuski, Anton and Traum, David},
  booktitle = {Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10)},
  date      = {2010-05},
  title     = {{NPCE}ditor: A Tool for Building Question-Answering Characters},
  publisher = {European Language Resources Association (ELRA)},
  url       = {http://www.lrec-conf.org/proceedings/lrec2010/pdf/660_Paper.pdf},
  urldate   = {2022-12-15},
  abstract  = {NPCEditor is a system for building and deploying virtual characters capable of engaging a user in spoken dialog on a limited domain. The dialogue may take any form as long as the character responses can be specified a priori. For example, NPCEditor has been used for constructing question answering characters where a user asks questions and the character responds, but other scenarios are possible. At the core of the system is a state of the art statistical language classification technology for mapping from user's text input to system responses. NPCEditor combines the classifier with a database that stores the character information and relevant language data, a server that allows the character designer to deploy the completed characters, and a user-friendly editor that helps the designer to accomplish both character design and deployment tasks. In the paper we define the overall system architecture, describe individual NPCEditor components, and guide the reader through the steps of building a virtual character.},
}

@InProceedings{Traum2015a,
  author    = {Traum, David and Georgila, Kallirroi and Artstein, Ron and Leuski, Anton},
  booktitle = {Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
  date      = {2015-09},
  title     = {Evaluating Spoken Dialogue Processing for Time-Offset Interaction},
  doi       = {10.18653/v1/W15-4629},
  location  = {Prague, Czech Republic},
  pages     = {199--208},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/W15-4629},
}

@Report{Hessen2020,
  author      = {van Hessen, Arjan},
  date        = {2020-08-01},
  institution = {SURF},
  title       = {Automatische spraakherkenning - Hoe kun je het inzetten voor onderwijsmateriaal?},
  type        = {resreport},
  urldate     = {2022-12-15},
}

@Article{Ning2019,
  author         = {Ning, Yishuang and He, Sheng and Wu, Zhiyong and Xing, Chunxiao and Zhang, Liang-Jie},
  date           = {2019},
  journaltitle   = {Applied Sciences},
  title          = {A Review of Deep Learning Based Speech Synthesis},
  doi            = {10.3390/app9194050},
  issn           = {2076-3417},
  number         = {19},
  url            = {https://www.mdpi.com/2076-3417/9/19/4050},
  volume         = {9},
  abstract       = {Speech synthesis, also known as text-to-speech (TTS), has attracted increasingly more attention. Recent advances on speech synthesis are overwhelmingly contributed by deep learning or even end-to-end techniques which have been utilized to enhance a wide range of application scenarios such as intelligent speech interaction, chatbot or conversational artificial intelligence (AI). For speech synthesis, deep learning based techniques can leverage a large scale of &lt;text, speech&gt; pairs to learn effective feature representations to bridge the gap between text and speech, thus better characterizing the properties of events. To better understand the research dynamics in the speech synthesis field, this paper firstly introduces the traditional speech synthesis methods and highlights the importance of the acoustic modeling from the composition of the statistical parametric speech synthesis (SPSS) system. It then gives an overview of the advances on deep learning based speech synthesis, including the end-to-end approaches which have achieved start-of-the-art performance in recent years. Finally, it discusses the problems of the deep learning methods for speech synthesis, and also points out some appealing research directions that can bring the speech synthesis research into a new frontier.},
  article-number = {4050},
}

@Online{Jia2019,
  author = {Jia, Ye and Weiss, Ron},
  date   = {2019-05-15},
  title  = {Introducing Translatotron: An End-to-End Speech-to-Speech Translation Model},
  url    = {https://ai.googleblog.com/2019/05/introducing-translatotron-end-to-end.html},
}

@Misc{Bryson2013,
  author        = {Steve Bryson},
  title         = {Virtual Reality: A Definition History - A Personal Essay},
  eprint        = {1312.4322},
  archiveprefix = {arXiv},
  primaryclass  = {cs.HC},
  year          = {2013},
}

@InProceedings{Boas2012,
  author = {Yuri Antonio Gonçalves Vilas Boas},
  title  = {Overview of Virtual Reality Technologies},
  year   = {2012},
}

@Article{Anggraini2018,
  author  = {Anggraini, Nenny and Kuniawan, Angga and Wardhani, Luh and Hakiem, Nashrul},
  title   = {Speech Recognition Application for the Speech Impaired using the Android-based Google Cloud Speech API},
  doi     = {10.12928/TELKOMNIKA.v16i6.9638},
  pages   = {2733-2739},
  volume  = {16},
  journal = {Telkomnika (Telecommunication Computing Electronics and Control)},
  month   = {12},
  year    = {2018},
}

@Article{Wang2021,
  author       = {Hui Hui Wang},
  date         = {2021},
  journaltitle = {Journal of IT in Asia},
  title        = {Speech Recorder and Translator using Google Cloud Speech-to-Text and Translation},
}

@Article{Woollacott2021,
  author  = {Woollacott, Adam and Design, VI},
  title   = {Benchmarking speech technologies},
  journal = {Academia. edu, Feb},
  year    = {2021},
}


@Article{Xu2021,
  author       = {Binbin Xu and Chongyang Tao and Zidu Feng and Youssef Raqui and Sylvie Ranwez},
  date         = {2021},
  journaltitle = {CoRR},
  title        = {A Benchmarking on Cloud based Speech-To-Text Services for French Speech and Background Noise Effect},
  eprint       = {2105.03409},
  eprinttype   = {arXiv},
  url          = {https://arxiv.org/abs/2105.03409},
  volume       = {abs/2105.03409},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2105-03409.bib},
  timestamp    = {Sun, 06 Jun 2021 10:37:49 +0200},
}

@Manual{Amazon2023,
  author = {Amazon},
  date   = {2023-01-01},
  title  = {Amazon Transcribe: Developer Guide},
  url    = {https://aws.amazon.com/transcribe},
}

@InProceedings{Chee2009,
  author = {Lim Sin Chee and Ooi Chia Ai and Sazali Bin Yaacob and Jejawi Perlis},
  title  = {Overview of Automatic Stuttering Recognition System},
  year   = {2009},
}

@Article{Gordon2002,
  author    = {Gordon, Neil},
  title     = {Stuttering: incidence and causes},
  doi       = {10.1017/S0012162201002067},
  number    = {4},
  pages     = {278–282},
  volume    = {44},
  journal   = {Developmental Medicine and Child Neurology},
  publisher = {Cambridge University Press},
  year      = {2002},
}

@Article{Alharbi2021,
  author  = {Alharbi, Sadeen and Alrazgan, Muna and Alrashed, Alanoud and Alnomasi, Turkiayh and Almojel, Raghad and Alharbi, Rimah and Alharbi, Saja and Alturki, Sahar and Alshehri, Fatimah and Almojil, Maha},
  title   = {Automatic Speech Recognition: Systematic Literature Review},
  doi     = {10.1109/ACCESS.2021.3112535},
  pages   = {131858-131876},
  volume  = {9},
  journal = {IEEE Access},
  year    = {2021},
}

@InProceedings{Sun2019,
  author    = {Chi Sun and Xipeng Qiu and Yige Xu and Xuanjing Huang},
  booktitle = {China National Conference on Chinese Computational Linguistics},
  title     = {How to Fine-Tune BERT for Text Classification?},
  url       = {https://api.semanticscholar.org/CorpusID:153312532},
  year      = {2019},
}

@Misc{Liu2019,
  author        = {Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
  title         = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  eprint        = {1907.11692},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  year          = {2019},
}

@InProceedings{Manjula2019,
  author    = {Manjula, G. and Shivakumar, M. and Geetha, Y. V.},
  booktitle = {Proceedings of the 3rd International Conference on Cryptography, Security and Privacy},
  title     = {Adaptive Optimization Based Neural Network for Classification of Stuttered Speech},
  doi       = {10.1145/3309074.3309113},
  isbn      = {9781450366182},
  location  = {Kuala Lumpur, Malaysia},
  pages     = {93–98},
  publisher = {Association for Computing Machinery},
  series    = {ICCSP '19},
  url       = {https://doi.org/10.1145/3309074.3309113},
  abstract  = {Stuttering, also known as stammering is a speech disorder in which the fluency of speech is interrupted by occurrences of dysfluencies like repetitions, prolongations, and blocks or articulatory fixations. This work is intended to develop automatic recognition procedure to assess stuttering disfluencies (Repetitions, Prolongations and Blocks). For predicting the speech dysfluencies, we have employed an effective Adaptive Optimization based Artificial Neural Network (AOANN) approach. Moreover, the proposed technique employs the Mel Frequency Cepstral Coefficient (MFCC) features is implemented to test its effectiveness. The experimental investigations reveal that the proposed method shows promising results in distinguishing between three stuttering events repetitions, prolongations and blocks.},
  address   = {New York, NY, USA},
  keywords  = {mel frequency cepstral coefficient features, adaptive optimization based artificial neural network, stuttered events},
  numpages  = {6},
  year      = {2019},
}

@InProceedings{Suryaa2017AutomaticSR,
  author = {Arya A Suryaa and Surekha Mariam Vargheseb},
  title  = {Automatic Speech Recognition System for Stuttering Disabled Persons},
  url    = {https://api.semanticscholar.org/CorpusID:212570213},
  year   = {2017},
}

@Comment{jabref-meta: databaseType:biblatex;}
